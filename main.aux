\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {0.1}Abstract}{2}{section.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{5}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{Introduction}{5}{chapter.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{9}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Related Work}{9}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Near Infrared Spectroscopy (NIRS)}{9}{section.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Example near-infrared spectra illustrating reflectance across wavelengths. Each line represents a unique sample, showing how NIRS captures molecular absorption/reflectance patterns.}}{10}{figure.2.1}\protected@file@percent }
\newlabel{Figure 5}{{2.1}{10}{Example near-infrared spectra illustrating reflectance across wavelengths. Each line represents a unique sample, showing how NIRS captures molecular absorption/reflectance patterns}{figure.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Liquid Chromatography Mass Spectrometry}{11}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}R Programming}{11}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Machine Learning}{12}{section.2.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Different machine learning models illustrating the four primary learning methods: supervised, unsupervised, semi-supervised, and reinforcement learning.}}{13}{figure.2.2}\protected@file@percent }
\newlabel{Figure 1}{{2.2}{13}{Different machine learning models illustrating the four primary learning methods: supervised, unsupervised, semi-supervised, and reinforcement learning}{figure.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Partial Least Square Regression (PLSR)}{14}{subsection.2.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces A comparison of PCA (A) and PLS (B). In the PCA plot, the x-axis represents a combination of variables (e.g., three metabolites) that captures the greatest variation in the dataset, independent of group classification. In contrast, PLS focuses on explaining the relationship with an explanatory variable, such as "Treatment" in this example}}{14}{figure.2.3}\protected@file@percent }
\newlabel{Figure 2}{{2.3}{14}{A comparison of PCA (A) and PLS (B). In the PCA plot, the x-axis represents a combination of variables (e.g., three metabolites) that captures the greatest variation in the dataset, independent of group classification. In contrast, PLS focuses on explaining the relationship with an explanatory variable, such as "Treatment" in this example}{figure.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Random Forest (RF)}{15}{subsection.2.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Schematic representation of a Random Forest model.}}{15}{figure.2.4}\protected@file@percent }
\newlabel{Figure 3}{{2.4}{15}{Schematic representation of a Random Forest model}{figure.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.3}Convolutional Neural Network (CNN)}{16}{subsection.2.5.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Comparison of artificial neurons and real neurons}}{16}{figure.2.5}\protected@file@percent }
\newlabel{Figure 4}{{2.5}{16}{Comparison of artificial neurons and real neurons}