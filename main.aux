\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Abstract}{2}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Introduction}{4}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Near Infrared Spectroscopy (NIRS)}{8}{section.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Example near-infrared spectra illustrating reflectance across wavelengths. Each line represents a unique sample, showing how NIRS captures molecular absorption/reflectance patterns.}}{8}{figure.1}\protected@file@percent }
\newlabel{Figure 5}{{1}{8}{Example near-infrared spectra illustrating reflectance across wavelengths. Each line represents a unique sample, showing how NIRS captures molecular absorption/reflectance patterns}{figure.1}{}}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {\textcolor {darkblue}{NIRS Instruments}}}{9}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Liquid Chromatography Mass Spectrometry}{10}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}R Programming}{10}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Machine Learning}{12}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\textcolor {darkblue}{Supervised Learning}}{12}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\textcolor {darkblue}{Unsupervised Learning}}{12}{section*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\textcolor {darkblue}{Semi-supervised and Reinforcement Learning}}{12}{section*.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Different machine learning models illustrating the four primary learning methods: supervised, unsupervised, semi-supervised, and reinforcement learning.}}{13}{figure.2}\protected@file@percent }
\newlabel{Figure 1}{{2}{13}{Different machine learning models illustrating the four primary learning methods: supervised, unsupervised, semi-supervised, and reinforcement learning}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Partial Least Square Regression (PLSR)}{13}{subsection.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces A comparison of PCA (A) and PLS (B). In the PCA plot, the x-axis represents a combination of variables (e.g., three metabolites) that captures the greatest variation in the dataset, independent of group classification. In contrast, PLS focuses on explaining the relationship with an explanatory variable, such as "Treatment" in this example}}{14}{figure.3}\protected@file@percent }
\newlabel{Figure 2}{{3}{14}{A comparison of PCA (A) and PLS (B). In the PCA plot, the x-axis represents a combination of variables (e.g., three metabolites) that captures the greatest variation in the dataset, independent of group classification. In contrast, PLS focuses on explaining the relationship with an explanatory variable, such as "Treatment" in this example}{figure.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Random Forest (RF)}{14}{subsection.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Schematic representation of a Random Forest model.}}{15}{figure.4}\protected@file@percent }
\newlabel{Figure 3}{{4}{15}{Schematic representation of a Random Forest model}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Convolutional Neural Network (CNN)}{15}{subsection.5.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Comparison of artificial neurons and real neurons}}{16}{figure.5}\protected@file@percent }
\newlabel{Figure 4}{{5}{16}{Comparison of artificial neurons and real neurons}{figure.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}R Toolbox Development}{17}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Toolbox: nearspectRa}{17}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Functions of nearspectRa}{17}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Development process}{18}{subsection.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Usage and Integration}{18}{subsection.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Challenges and Future Work}{18}{subsection.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Contributions elsewhere}{18}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}HPC runs}{18}{section.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9}Data charecterestics}{18}{section.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10}Baseline Machine Learning Models Pablo}{19}{section.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1}Variable importance}{19}{subsection.10.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11} Variations in Baseline systems}{19}{section.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.1} modifying the Test and Training split}{19}{subsection.11.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2} input data length}{19}{subsection.11.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12}Sues}{19}{section.12}\protected@file@percent }
\gdef \@abspage@last{22}
