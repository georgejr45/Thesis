\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{5}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{9}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Near Infrared Spectroscopy (NIRS)}{9}{section.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Example near-infrared spectra illustrating reflectance across wavelengths. Each line represents a unique sample, showing how NIRS captures molecular absorption/reflectance patterns. The data is from the project [15]}}{10}{figure.2.1}\protected@file@percent }
\newlabel{fig:nirs_spectra}{{2.1}{10}{Example near-infrared spectra illustrating reflectance across wavelengths. Each line represents a unique sample, showing how NIRS captures molecular absorption/reflectance patterns. The data is from the project [15]}{figure.2.1}{}}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {\textcolor {darkblue}{NIRS Instruments}}}{11}{section*.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces ASD FieldSpec 4 instrument for measuring NIRS data.\\ \url  {https://www.malvernpanalytical.com}}}{11}{figure.2.2}\protected@file@percent }
\newlabel{fig:fieldspec4}{{2.2}{11}{ASD FieldSpec 4 instrument for measuring NIRS data.\\ \url {https://www.malvernpanalytical.com}}{figure.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Liquid Chromatography Mass Spectrometry}{11}{section.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces SVC HR-1024i instrument for measuring NIRS data.\\ \url  {https://spectravista.com}}}{12}{figure.2.3}\protected@file@percent }
\newlabel{fig:svc}{{2.3}{12}{SVC HR-1024i instrument for measuring NIRS data.\\ \url {https://spectravista.com}}{figure.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces LCMS dataset after initial processing using the \texttt  {metabolighteR} package, revealing the selected columns relevant for downstream analysis [14].}}{12}{figure.2.4}\protected@file@percent }
\newlabel{fig:lcms_raw}{{2.4}{12}{LCMS dataset after initial processing using the \texttt {metabolighteR} package, revealing the selected columns relevant for downstream analysis [14]}{figure.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}R Programming}{13}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Machine Learning}{14}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\textcolor {darkblue}{Supervised Learning}}{14}{section*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\textcolor {darkblue}{Unsupervised Learning}}{14}{section*.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Different machine learning models illustrating the four primary learning methods: supervised, unsupervised, semi-supervised, and reinforcement learning.}}{15}{figure.2.5}\protected@file@percent }
\newlabel{fig:ml}{{2.5}{15}{Different machine learning models illustrating the four primary learning methods: supervised, unsupervised, semi-supervised, and reinforcement learning}{figure.2.5}{}}
\@writefile{toc}{\contentsline {paragraph}{\textcolor {darkblue}{Semi-supervised and Reinforcement Learning}}{15}{section*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Partial Least Square Regression (PLSR)}{15}{subsection.2.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces A comparison of PCA (A) and PLS (B). In the PCA plot, the PC1(x-axis) represents a combination of variables (e.g., three metabolites) that captures the greatest variation in the dataset, independent of group classification. In contrast, PLS focuses on explaining the relationship with an explanatory variable, such as "Treatment" in this example}}{16}{figure.2.6}\protected@file@percent }
\newlabel{fig:plsr}{{2.6}{16}{A comparison of PCA (A) and PLS (B). In the PCA plot, the PC1(x-axis) represents a combination of variables (e.g., three metabolites) that captures the greatest variation in the dataset, independent of group classification. In contrast, PLS focuses on explaining the relationship with an explanatory variable, such as "Treatment" in this example}{figure.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Random Forest (RF)}{17}{subsection.2.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Schematic representation of a Random Forest model (classification).}}{18}{figure.2.7}\protected@file@percent }
\newlabel{fig:rf}{{2.7}{18}{Schematic representation of a Random Forest model (classification)}{figure.2.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Convolutional Neural Network (CNN)}{19}{subsection.2.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Schematic representation of Convolutional Neural Network }}{20}{figure.2.8}\protected@file@percent }
\newlabel{fig:cnn}{{2.8}{20}{Schematic representation of Convolutional Neural Network}{figure.2.8}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Implementation}{23}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}R Toolbox Development}{23}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Toolbox: nearspectRa}{23}{subsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Functions of nearspectRa}{23}{subsection.3.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Example output of the \texttt  {read\_summarizedexperiment\_asd function}}}{25}{figure.3.1}\protected@file@percent }
\newlabel{Figure 2}{{3.1}{25}{Example output of the \texttt {read\_summarizedexperiment\_asd function}}{figure.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Example output of the \texttt  {read\_summarizedexperiment\_sig function}}}{26}{figure.3.2}\protected@file@percent }
\newlabel{Figure 2}{{3.2}{26}{Example output of the \texttt {read\_summarizedexperiment\_sig function}}{figure.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Package Development Overview}{26}{subsection.3.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}Usage and Integration}{27}{subsection.3.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.5}Challenges and Future Work}{27}{subsection.3.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Contributions elsewhere}{27}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}GitHub Actions to R-FieldSpectra}{27}{subsection.3.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Contribution of GitHub Actions to the R-FieldSpectra package. \\ \url  {https://github.com/serbinsh/R-FieldSpectra/pull/24/commits}}}{28}{figure.3.3}\protected@file@percent }
\newlabel{fig:github_actions}{{3.3}{28}{Contribution of GitHub Actions to the R-FieldSpectra package. \\ \url {https://github.com/serbinsh/R-FieldSpectra/pull/24/commits}}{figure.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Contribution of the read.sig Function to R-FieldSpectra}{28}{subsection.3.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Example output of read.sig function}}{29}{figure.3.4}\protected@file@percent }
\newlabel{fig:read_sig}{{3.4}{29}{Example output of read.sig function}{figure.3.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Prediction of Leaf Traits From NIRS Data}{29}{section.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces A simplified workflow displying the process of trait prediction from NIRS data}}{30}{figure.3.5}\protected@file@percent }
\newlabel{fig:nirs_workflow}{{3.5}{30}{A simplified workflow displying the process of trait prediction from NIRS data}{figure.3.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Leaf traits and their ecological function along with list of literature describing them. The traits are colored differently according to the leaf economics spectrum (LES) [15]}}{31}{figure.3.6}\protected@file@percent }
\newlabel{fig:traits}{{3.6}{31}{Leaf traits and their ecological function along with list of literature describing them. The traits are colored differently according to the leaf economics spectrum (LES) [15]}{figure.3.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Trait Prediction Using PLSR}{31}{subsection.3.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Component SLA before scaling}}{33}{figure.3.7}\protected@file@percent }
\newlabel{fig:snv1}{{3.7}{33}{Component SLA before scaling}{figure.3.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Component SLA after scaling}}{33}{figure.3.8}\protected@file@percent }
\newlabel{fig:snv2}{{3.8}{33}{Component SLA after scaling}{figure.3.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Summary of PLSR model for SLA trait, explaining the data dimension used for creating the model and the number of components considered}}{35}{figure.3.9}\protected@file@percent }
\newlabel{fig:plsr_model}{{3.9}{35}{Summary of PLSR model for SLA trait, explaining the data dimension used for creating the model and the number of components considered}{figure.3.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Plot of PLSR model for SLA trait prediction illustrating how the number of components were selected}}{36}{figure.3.10}\protected@file@percent }
\newlabel{fig:plsr_sla_model}{{3.10}{36}{Plot of PLSR model for SLA trait prediction illustrating how the number of components were selected}{figure.3.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces The scatter plot created using ggplot2 package, illustrating the predicted and actual SLA values }}{38}{figure.3.11}\protected@file@percent }
\newlabel{fig:sla_plsr}{{3.11}{38}{The scatter plot created using ggplot2 package, illustrating the predicted and actual SLA values}{figure.3.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces Illustrate output of the \texttt  {perform\_PLSR} function}}{39}{figure.3.12}\protected@file@percent }
\newlabel{fig:model_ldmc}{{3.12}{39}{Illustrate output of the \texttt {perform\_PLSR} function}{figure.3.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1.1}Extrapolation study of PLSR}{41}{subsubsection.3.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1.2}Variable importance in PLSR}{43}{subsubsection.3.3.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces The scatter plot illustrates the predicted versus actual SLA values for the extrapolation of the PLSR model on the upper data range.}}{44}{figure.3.13}\protected@file@percent }
\newlabel{fig:extra_h_plsr}{{3.13}{44}{The scatter plot illustrates the predicted versus actual SLA values for the extrapolation of the PLSR model on the upper data range}{figure.3.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Trait Prediction Using Random Forest}{45}{subsection.3.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.14}{\ignorespaces The variable importance plot of PLSR model, illustrating the contribution deapth of different features during SLA trait prediction. The importance scores are given in the Y axis and higher the score more significant the corresponding wavelength is in predicting SLA trait of a plant. }}{46}{figure.3.14}\protected@file@percent }
\newlabel{fig:vi_sla_plsr}{{3.14}{46}{The variable importance plot of PLSR model, illustrating the contribution deapth of different features during SLA trait prediction. The importance scores are given in the Y axis and higher the score more significant the corresponding wavelength is in predicting SLA trait of a plant}{figure.3.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.15}{\ignorespaces The scatter plot created using ggplot2 package, illustrating the predicted and actual SLA values of random forest model}}{49}{figure.3.15}\protected@file@percent }
\newlabel{fig:sla_rf}{{3.15}{49}{The scatter plot created using ggplot2 package, illustrating the predicted and actual SLA values of random forest model}{figure.3.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.16}{\ignorespaces The scatter plot illustrates the predicted versus actual SLA values for the extrapolation of the random forest model on the upper data range}}{50}{figure.3.16}\protected@file@percent }
\newlabel{fig:extra_h_rf}{{3.16}{50}{The scatter plot illustrates the predicted versus actual SLA values for the extrapolation of the random forest model on the upper data range}{figure.3.16}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2.1}Variable importance in RF}{50}{subsubsection.3.3.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.17}{\ignorespaces Variable importance graph of SLA trait in random forest model}}{51}{figure.3.17}\protected@file@percent }
\newlabel{fig:vi_sla_rf}{{3.17}{51}{Variable importance graph of SLA trait in random forest model}{figure.3.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Trait Prediction Using Convolutional Neural Network}{52}{subsection.3.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.18}{\ignorespaces Q-Q plot (left) illustrating normality of SLA and histogram (right) showing the distribution of SLA [15]}}{53}{figure.3.18}\protected@file@percent }
\newlabel{fig:hist_CNN}{{3.18}{53}{Q-Q plot (left) illustrating normality of SLA and histogram (right) showing the distribution of SLA [15]}{figure.3.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.19}{\ignorespaces CNN model architecture and parameters summary. This table summarizes the structure of the Convolutional Neural Network (CNN) used for SLA prediction. It includes details on each layer, output shape, and the number of trainable parameters.}}{55}{figure.3.19}\protected@file@percent }
\newlabel{fig:cnn_model}{{3.19}{55}{CNN model architecture and parameters summary. This table summarizes the structure of the Convolutional Neural Network (CNN) used for SLA prediction. It includes details on each layer, output shape, and the number of trainable parameters}{figure.3.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.20}{\ignorespaces The CNN training model for SLA trait, illustrating the training and validation loss during training the model. The model's training was set to 5000 epoches and it stopped before reaching 1500 epoches.}}{57}{figure.3.20}\protected@file@percent }
\newlabel{fig:sla_traing_cnn}{{3.20}{57}{The CNN training model for SLA trait, illustrating the training and validation loss during training the model. The model's training was set to 5000 epoches and it stopped before reaching 1500 epoches}{figure.3.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.21}{\ignorespaces This plot illustrates the predictive ability of CNN for SLA trait}}{58}{figure.3.21}\protected@file@percent }
\newlabel{fig:sla_cnn}{{3.21}{58}{This plot illustrates the predictive ability of CNN for SLA trait}{figure.3.21}{}}
\@writefile{toc}{\contentsline 