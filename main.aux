\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{5}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{9}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Near Infrared Spectroscopy (NIRS)}{9}{section.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Example near-infrared spectra illustrating reflectance across wavelengths. Each line represents a unique sample, showing how NIRS captures molecular absorption/reflectance patterns.}}{10}{figure.2.1}\protected@file@percent }
\newlabel{Figure 5}{{2.1}{10}{Example near-infrared spectra illustrating reflectance across wavelengths. Each line represents a unique sample, showing how NIRS captures molecular absorption/reflectance patterns}{figure.2.1}{}}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {\textcolor {darkblue}{NIRS Instruments}}}{11}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Liquid Chromatography Mass Spectrometry}{11}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}R Programming}{12}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Machine Learning}{13}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\textcolor {darkblue}{Supervised Learning}}{13}{section*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\textcolor {darkblue}{Unsupervised Learning}}{14}{section*.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Different machine learning models illustrating the four primary learning methods: supervised, unsupervised, semi-supervised, and reinforcement learning.}}{14}{figure.2.2}\protected@file@percent }
\newlabel{Figure 1}{{2.2}{14}{Different machine learning models illustrating the four primary learning methods: supervised, unsupervised, semi-supervised, and reinforcement learning}{figure.2.2}{}}
\@writefile{toc}{\contentsline {paragraph}{\textcolor {darkblue}{Semi-supervised and Reinforcement Learning}}{14}{section*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Partial Least Square Regression (PLSR)}{15}{subsection.2.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces A comparison of PCA (A) and PLS (B). In the PCA plot, the x-axis represents a combination of variables (e.g., three metabolites) that captures the greatest variation in the dataset, independent of group classification. In contrast, PLS focuses on explaining the relationship with an explanatory variable, such as "Treatment" in this example}}{15}{figure.2.3}\protected@file@percent }
\newlabel{Figure 2}{{2.3}{15}{A comparison of PCA (A) and PLS (B). In the PCA plot, the x-axis represents a combination of variables (e.g., three metabolites) that captures the greatest variation in the dataset, independent of group classification. In contrast, PLS focuses on explaining the relationship with an explanatory variable, such as "Treatment" in this example}{figure.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Random Forest (RF)}{16}{subsection.2.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Schematic representation of a Random Forest model (classification).}}{16}{figure.2.4}\protected@file@percent }
\newlabel{Figure 3}{{2.4}{16}{Schematic representation of a Random Forest model (classification)}{figure.2.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2.1}Mathematical Explanation of Random Forest Regression}{17}{su